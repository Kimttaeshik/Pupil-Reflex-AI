{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkAIZnBukiNajMMnggqyFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimttaeshik/Pupil-Reflex-AI/blob/main/PupilReflexAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "부연 설명\n",
        "os와 cv2 라이브러리를 사용해 데이터 디렉토리를 탐색하고 이미지를 로드합니다.\n",
        "레이블 분류: 폴더 구조가 0/ (비정상)과 1/ (정상)처럼 구성되어 있다고 가정합니다.\n",
        "이미지를 정규화(0~1)하여 학습 안정성을 높입니다.\n",
        "이미지 크기 조정: img_size=(64, 64)는 기본 크기입니다. GPU 메모리와 모델 성능에 맞게 크기를 조정할 수 있습니다."
      ],
      "metadata": {
        "id": "lLMPmEM4lawT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcZdinacjXbQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 로드 및 전처리 함수\n",
        "def load_data(data_dir, img_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    데이터셋 디렉토리에서 이미지를 로드하고 전처리합니다.\n",
        "    - 이미지를 회색조로 변환\n",
        "    - 지정된 크기로 리사이즈\n",
        "    - 정규화 (0~1 사이 값으로 변환)\n",
        "\n",
        "    Parameters:\n",
        "        data_dir (str): 데이터셋 디렉토리 경로\n",
        "        img_size (tuple): 이미지 크기 (기본값 64x64)\n",
        "\n",
        "    Returns:\n",
        "        images (np.array): 전처리된 이미지 배열\n",
        "        labels (np.array): 이미지 레이블 배열\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label, sub_dir in enumerate(os.listdir(data_dir)):  # 서브 디렉토리를 기준으로 레이블 설정\n",
        "        sub_dir_path = os.path.join(data_dir, sub_dir)\n",
        "        for img_file in os.listdir(sub_dir_path):\n",
        "            img_path = os.path.join(sub_dir_path, img_file)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # 회색조 변환\n",
        "            img = cv2.resize(img, img_size)  # 리사이즈\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    images = np.array(images) / 255.0  # 정규화\n",
        "    labels = np.array(labels)\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "부연 설명\n",
        "train_test_split를 사용해 데이터를 80% 학습, 20% 테스트로 나눕니다.\n",
        "CNN 입력 형식: (64, 64, 1)은 CNN 모델이 요구하는 이미지 형식입니다. 마지막 차원 1은 회색조 이미지를 나타냅니다.\n",
        "데이터 불균형이 있다면, stratify=labels를 추가해 균형을 맞출 수 있습니다.\n"
      ],
      "metadata": {
        "id": "zyEt2bH7lpaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 로드\n",
        "data_dir = 'path_to_dataset'  # 데이터셋 경로\n",
        "images, labels = load_data(data_dir)\n",
        "\n",
        "# 데이터 분리 (학습/테스트 세트)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# CNN 입력 형식으로 데이터 변환\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n"
      ],
      "metadata": {
        "id": "JWvCuFZGlGl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "부연 설명\n",
        "Conv2D와 MaxPooling2D: 특징 추출과 다운샘플링을 담당합니다.\n",
        "Dropout: 과적합 방지를 위해 사용됩니다. Dropout 비율은 데이터 크기와 모델 복잡도에 따라 조정 가능합니다.\n",
        "Data Augmentation: 데이터 양이 적을 경우, 데이터 증강을 통해 모델의 일반화를 개선합니다. 필요에 따라 증강 파라미터를 조정하세요.\n",
        "Epochs: 학습 데이터 크기에 따라 10~50 epochs를 실험해 최적 값을 찾으세요.\n"
      ],
      "metadata": {
        "id": "ixljArl5luIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# CNN 모델 생성\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),  # 과적합 방지\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # 과적합 방지\n",
        "    Dense(1, activation='sigmoid')  # 이진 분류\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 데이터 증강\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,  # 회전\n",
        "    width_shift_range=0.1,  # 가로 이동\n",
        "    height_shift_range=0.1,  # 세로 이동\n",
        "    horizontal_flip=True  # 좌우 반전\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20\n",
        ")\n"
      ],
      "metadata": {
        "id": "oBaYcWJclIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "부연 설명\n",
        "평가 결과: 테스트 데이터에서 모델 성능을 확인합니다. accuracy가 80% 이상이면 성능이 적절하다고 판단할 수 있습니다.\n",
        "저장: 학습된 모델은 model.save()로 저장하고 나중에 로드해 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "mvEc4i2llw7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
        "\n",
        "# 모델 저장\n",
        "model.save('pupil_reflex_model.h5')\n"
      ],
      "metadata": {
        "id": "U2A5RzwJlPmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "부연 설명\n",
        "사용자 입력 이미지: 경로를 통해 입력된 이미지를 학습 데이터와 동일한 전처리를 거쳐 예측합니다.\n",
        "결과 해석: 모델 출력이 0.5 이상이면 \"정상 반응\", 그렇지 않으면 \"비정상 반응\"으로 분류합니다."
      ],
      "metadata": {
        "id": "MxT4VArfl4qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_pupil_reflex(image_path):\n",
        "    \"\"\"\n",
        "    저장된 모델을 사용해 새로운 이미지를 예측합니다.\n",
        "\n",
        "    Parameters:\n",
        "        image_path (str): 예측할 이미지 경로\n",
        "\n",
        "    Returns:\n",
        "        str: 예측 결과 (정상 반응 / 비정상 반응)\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (64, 64)) / 255.0\n",
        "    img = img.reshape(1, 64, 64, 1)\n",
        "    prediction = model.predict(img)\n",
        "    return \"정상 반응\" if prediction[0] > 0.5 else \"비정상 반응\"\n",
        "\n",
        "# 예측 테스트\n",
        "test_image = 'path_to_test_image.jpg'\n",
        "result = predict_pupil_reflex(test_image)\n",
        "print(f'테스트 이미지 결과: {result}')\n"
      ],
      "metadata": {
        "id": "ciC0K8S7lUL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용자 및 정확도에 영향을 미치는 조정 요소\n",
        "이미지 크기:\n",
        "GPU 메모리와 학습 시간을 고려해 (64, 64) 크기를 조정합니다. 큰 크기는 더 많은 정보를 포함하지만 처리 시간이 증가합니다.\n",
        "데이터 양:\n",
        "데이터가 부족하면 증강 기법을 사용하거나 Transfer Learning을 통해 사전 학습된 모델(VGG, ResNet 등)을 활용할 수 있습니다.\n",
        "과적합 방지:\n",
        "Dropout 비율(0.25~0.5)과 학습 데이터를 균형 있게 설정하세요.\n",
        "학습 파라미터:\n",
        "batch_size, epochs, learning_rate 등을 조정해 최적의 성능을 찾으세요.\n",
        "이 코드는 전체 파이프라인을 설계한 예입니다. 각 단계에서 테스트와 조정을 반복해 최적의 모델을 개발하세요.\n"
      ],
      "metadata": {
        "id": "lMzMhv9ilWg7"
      }
    }
  ]
}